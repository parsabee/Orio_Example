__global__ void orcu_kernel5042(const int n, double* y, double* x) {
  const int tid=blockIdx.x*blockDim.x+threadIdx.x;
  const int gsize=gridDim.x*blockDim.x;
  __shared__ double shared_y[64];
  __shared__ double shared_x[64];
  for (int i=tid; i<=n-1; i+=gsize) {
    shared_y[threadIdx.x]=y[i];
    shared_x[threadIdx.x]=x[i];
    shared_y[threadIdx.x]=shared_y[threadIdx.x]+shared_x[threadIdx.x];
    y[i]=shared_y[threadIdx.x];
  }
}
typedef struct {
    double *data;
} MX;

void VecXPY(int n, MX *X, MX *Y) {
  double *x = X->data;
  double *y = Y->data;
  register int i;
  /*@ begin PerfTuning(
        def performance_params {
          param TC[] = [32, 64];
          param BC[] = range(14,29,14);
          param SC[] = range(1,3);
          param CB[] = [True, False];
          param PL[] = [16];
          param CFLAGS[] = [''];
        }
        def build {
          arg build_command = 'nvcc -arch=sm_75 @CFLAGS';
        }
        def input_params {
          param N[] = [1000];
        }
        def input_vars {
          decl dynamic double y[N] = random;
          decl dynamic double x[N] = random;
        }
        def performance_counter {
          arg method = 'basic timer';
          arg repetitions = 1;
        }
  ) @*/
/**-- (Generated by Orio) 
Best performance cost: 
  [0.01328] 
Tuned for specific problem sizes: 
  N = 1000 
Best performance parameters: 
  BC = 28 
  CB = True 
  CFLAGS =  
  PL = 16 
  SC = 1 
  TC = 64 
--**/


  int n=N;

  /*@ begin Loop(transform CUDA(threadCount=TC, blockCount=BC, streamCount=SC, cacheBlocks=CB, preferL1Size=PL)

  for (i=0; i<=n-1; i++)
    y[i]+=x[i];

  ) @*/
  {
    cudaDeviceSynchronize();
    /*declare variables*/
    double* dev_y;
    double* dev_x;
    int nthreads=64;
    /*calculate device dimensions*/
    dim3 dimGrid, dimBlock;
    dimBlock.x=nthreads;
    dimGrid.x=28;
    /*allocate device memory*/
    cudaMalloc(&dev_y,N*sizeof(double));
    cudaMalloc(&dev_x,N*sizeof(double));
    cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
    /*copy data from host to device*/
    cudaEventRecord(tstart,0);
    cudaMemcpy(dev_y,y,N*sizeof(double),cudaMemcpyHostToDevice);
    cudaMemcpy(dev_x,x,N*sizeof(double),cudaMemcpyHostToDevice);
    cudaEventRecord(tstop,0);
    cudaEventSynchronize(tstop);
    cudaEventElapsedTime(&orcu_transfer,tstart,tstop);
    cudaEventRecord(start,0);
    /*invoke device kernel*/
    orcu_kernel5042<<<dimGrid,dimBlock>>>(n,dev_y,dev_x);
    cudaEventRecord(stop,0);
    cudaEventSynchronize(stop);
    cudaEventElapsedTime(&orcu_elapsed,start,stop);
    /*copy data from device to host*/
    cudaMemcpy(y,dev_y,N*sizeof(double),cudaMemcpyDeviceToHost);
    cudaDeviceSetCacheConfig(cudaFuncCachePreferNone);
    /*free allocated memory*/
    cudaFree(dev_y);
    cudaFree(dev_x);
    cudaError_t err=cudaGetLastError();
    if (cudaSuccess!=err) 
      printf("CUDA runtime error: %s@",cudaGetErrorString(err));
  }
  /*@ end @*/
    /*@ end @*/
}
